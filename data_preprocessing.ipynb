{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install keras-self-attention\n",
    "import os, time, gc, sys, io\n",
    "import datetime, pickle\n",
    "import warnings, random, pdb\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import mpl_toolkits.axisartist as AA\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from scipy import stats\n",
    "from pandas import Series\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowing(dfX,win,nvar,idx):\n",
    "    lX = np.lib.stride_tricks.sliding_window_view(dfX.to_numpy(), window_shape = win)[::nvar]\n",
    "    mX = pd.DataFrame.from_records(lX)\n",
    "    mX.set_index(idx,drop=True, inplace=True)\n",
    "    return(mX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL: NaNs are about 4% in the original dataset. Size: (2257, 18)\n",
      "ADBE: NaNs are about 4% in the original dataset. Size: (1790, 18)\n",
      "AMZN: NaNs are about 4% in the original dataset. Size: (2239, 18)\n",
      "AVGO: NaNs are about 4% in the original dataset. Size: (1613, 18)\n",
      "CMCSA: NaNs are about 4% in the original dataset. Size: (1901, 18)\n",
      "COST: NaNs are about 4% in the original dataset. Size: (1388, 18)\n",
      "CSCO: NaNs are about 4% in the original dataset. Size: (1994, 18)\n",
      "GOOG: NaNs are about 4% in the original dataset. Size: (2251, 18)\n",
      "GOOGL: NaNs are about 4% in the original dataset. Size: (2251, 18)\n",
      "META: NaNs are about 4% in the original dataset. Size: (2251, 18)\n",
      "MSFT: NaNs are about 4% in the original dataset. Size: (2253, 18)\n",
      "NVDA: NaNs are about 4% in the original dataset. Size: (2088, 18)\n",
      "PEP: NaNs are about 4% in the original dataset. Size: (1836, 18)\n",
      "TMUS: NaNs are about 4% in the original dataset. Size: (1774, 18)\n",
      "TSLA: NaNs are about 4% in the original dataset. Size: (2246, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TWITTER_SENTIMENT_DAILY_AVG</th>\n",
       "      <th>TWITTER_PUBLICATION_COUNT</th>\n",
       "      <th>TWITTER_NEG_SENTIMENT_COUNT</th>\n",
       "      <th>TWITTER_POS_SENTIMENT_COUNT</th>\n",
       "      <th>TWITTER_NEUTRAL_SENTIMENT_CNT</th>\n",
       "      <th>NEWS_SENTIMENT_DAILY_AVG</th>\n",
       "      <th>NEWS_PUBLICATION_COUNT</th>\n",
       "      <th>NEWS_NEG_SENTIMENT_COUNT</th>\n",
       "      <th>NEWS_POS_SENTIMENT_COUNT</th>\n",
       "      <th>NEWS_NEUTRAL_SENTIMENT_COUNT</th>\n",
       "      <th>PX_HIGH</th>\n",
       "      <th>PX_LOW</th>\n",
       "      <th>PX_OPEN</th>\n",
       "      <th>PX_LAST</th>\n",
       "      <th>VOLUME</th>\n",
       "      <th>RSI_14D</th>\n",
       "      <th>PX_TREND</th>\n",
       "      <th>PX_VTREND</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>0.0018</td>\n",
       "      <td>222.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0569</td>\n",
       "      <td>139.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>14.8833</td>\n",
       "      <td>14.2173</td>\n",
       "      <td>14.858</td>\n",
       "      <td>14.6207</td>\n",
       "      <td>71466645.0</td>\n",
       "      <td>59.8008</td>\n",
       "      <td>-0.0161</td>\n",
       "      <td>-1.150596e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            TWITTER_SENTIMENT_DAILY_AVG  TWITTER_PUBLICATION_COUNT  \\\n",
       "date                                                                 \n",
       "2015-01-02                       0.0018                      222.0   \n",
       "\n",
       "            TWITTER_NEG_SENTIMENT_COUNT  TWITTER_POS_SENTIMENT_COUNT  \\\n",
       "date                                                                   \n",
       "2015-01-02                          6.0                          9.0   \n",
       "\n",
       "            TWITTER_NEUTRAL_SENTIMENT_CNT  NEWS_SENTIMENT_DAILY_AVG  \\\n",
       "date                                                                  \n",
       "2015-01-02                          192.0                    0.0569   \n",
       "\n",
       "            NEWS_PUBLICATION_COUNT  NEWS_NEG_SENTIMENT_COUNT  \\\n",
       "date                                                           \n",
       "2015-01-02                   139.0                       3.0   \n",
       "\n",
       "            NEWS_POS_SENTIMENT_COUNT  NEWS_NEUTRAL_SENTIMENT_COUNT  PX_HIGH  \\\n",
       "date                                                                          \n",
       "2015-01-02                       7.0                          41.0  14.8833   \n",
       "\n",
       "             PX_LOW  PX_OPEN  PX_LAST      VOLUME  RSI_14D  PX_TREND  \\\n",
       "date                                                                   \n",
       "2015-01-02  14.2173   14.858  14.6207  71466645.0  59.8008   -0.0161   \n",
       "\n",
       "               PX_VTREND  \n",
       "date                      \n",
       "2015-01-02 -1.150596e+06  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"Datasets/\"\n",
    "stock_list= [\"AAPL\", \"ADBE\", \"AMZN\", \"AVGO\", \"CMCSA\", \"COST\", \"CSCO\", \"GOOG\", \"GOOGL\", \"META\", \"MSFT\", \"NVDA\", \"PEP\", \"TMUS\", \"TSLA\"]\n",
    "\n",
    "df_dict = {}\n",
    "df_result = pd.DataFrame(columns = ['MSEP', 'MSEY', 'Stock','Algo'])\n",
    "tot_res = {}\n",
    "#\n",
    "for stock in stock_list:\n",
    "    fich = path + stock +' US Equity_060124.csv'\n",
    "    df_dict[stock] = pd.read_csv(fich, sep = \",\",index_col=0,parse_dates=True)\n",
    "    df_dict[stock]['PX_TREND'] = 2*(df_dict[stock]['PX_LAST'] - \\\n",
    "                                    df_dict[stock]['PX_OPEN'])/(df_dict[stock]['PX_OPEN'] + \\\n",
    "                                                                df_dict[stock]['PX_LAST'])\n",
    "    df_dict[stock]['PX_VTREND']= df_dict[stock]['PX_TREND'] * df_dict[stock]['VOLUME']\n",
    "    nans = sum(df_dict[stock]['PX_OPEN'].isna())*100/df_dict[stock].shape[0]\n",
    "    df_dict[stock] = df_dict[stock].dropna()\n",
    "    # Adopted policy is to drop the NANs as they represent holidays or working off days\n",
    "    print('{}: NaNs are about {}% in the original dataset. Size: {}'.format(\\\n",
    "                                    stock,str(round(nans)),str(df_dict[stock].shape)))\n",
    "    tot_res['INP'] = df_dict\n",
    "\n",
    "df = df_dict['TSLA']\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2246 entries, 2015-01-02 to 2023-12-29\n",
      "Data columns (total 18 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   TWITTER_SENTIMENT_DAILY_AVG    2246 non-null   float64\n",
      " 1   TWITTER_PUBLICATION_COUNT      2246 non-null   float64\n",
      " 2   TWITTER_NEG_SENTIMENT_COUNT    2246 non-null   float64\n",
      " 3   TWITTER_POS_SENTIMENT_COUNT    2246 non-null   float64\n",
      " 4   TWITTER_NEUTRAL_SENTIMENT_CNT  2246 non-null   float64\n",
      " 5   NEWS_SENTIMENT_DAILY_AVG       2246 non-null   float64\n",
      " 6   NEWS_PUBLICATION_COUNT         2246 non-null   float64\n",
      " 7   NEWS_NEG_SENTIMENT_COUNT       2246 non-null   float64\n",
      " 8   NEWS_POS_SENTIMENT_COUNT       2246 non-null   float64\n",
      " 9   NEWS_NEUTRAL_SENTIMENT_COUNT   2246 non-null   float64\n",
      " 10  PX_HIGH                        2246 non-null   float64\n",
      " 11  PX_LOW                         2246 non-null   float64\n",
      " 12  PX_OPEN                        2246 non-null   float64\n",
      " 13  PX_LAST                        2246 non-null   float64\n",
      " 14  VOLUME                         2246 non-null   float64\n",
      " 15  RSI_14D                        2246 non-null   float64\n",
      " 16  PX_TREND                       2246 non-null   float64\n",
      " 17  PX_VTREND                      2246 non-null   float64\n",
      "dtypes: float64(18)\n",
      "memory usage: 333.4 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TWITTER_SENTIMENT_DAILY_AVG</th>\n",
       "      <th>TWITTER_PUBLICATION_COUNT</th>\n",
       "      <th>TWITTER_NEG_SENTIMENT_COUNT</th>\n",
       "      <th>TWITTER_POS_SENTIMENT_COUNT</th>\n",
       "      <th>TWITTER_NEUTRAL_SENTIMENT_CNT</th>\n",
       "      <th>NEWS_SENTIMENT_DAILY_AVG</th>\n",
       "      <th>NEWS_PUBLICATION_COUNT</th>\n",
       "      <th>NEWS_NEG_SENTIMENT_COUNT</th>\n",
       "      <th>NEWS_POS_SENTIMENT_COUNT</th>\n",
       "      <th>NEWS_NEUTRAL_SENTIMENT_COUNT</th>\n",
       "      <th>PX_HIGH</th>\n",
       "      <th>PX_LOW</th>\n",
       "      <th>PX_OPEN</th>\n",
       "      <th>PX_LAST</th>\n",
       "      <th>VOLUME</th>\n",
       "      <th>RSI_14D</th>\n",
       "      <th>PX_TREND</th>\n",
       "      <th>PX_VTREND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2246.000000</td>\n",
       "      <td>2246.000000</td>\n",
       "      <td>2246.000000</td>\n",
       "      <td>2246.000000</td>\n",
       "      <td>2246.000000</td>\n",
       "      <td>2246.000000</td>\n",
       "      <td>2246.000000</td>\n",
       "      <td>2246.000000</td>\n",
       "      <td>2246.000000</td>\n",
       "      <td>2246.000000</td>\n",
       "      <td>2246.000000</td>\n",
       "      <td>2246.000000</td>\n",
       "      <td>2246.000000</td>\n",
       "      <td>2246.000000</td>\n",
       "      <td>2.246000e+03</td>\n",
       "      <td>2246.000000</td>\n",
       "      <td>2246.000000</td>\n",
       "      <td>2.246000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.011724</td>\n",
       "      <td>2225.603295</td>\n",
       "      <td>243.328139</td>\n",
       "      <td>176.725289</td>\n",
       "      <td>1728.593945</td>\n",
       "      <td>-0.007657</td>\n",
       "      <td>786.969279</td>\n",
       "      <td>25.896260</td>\n",
       "      <td>18.248442</td>\n",
       "      <td>142.836598</td>\n",
       "      <td>105.859928</td>\n",
       "      <td>101.048998</td>\n",
       "      <td>103.517803</td>\n",
       "      <td>103.488381</td>\n",
       "      <td>1.146288e+08</td>\n",
       "      <td>52.864388</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>1.118767e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.065884</td>\n",
       "      <td>1892.479825</td>\n",
       "      <td>361.788078</td>\n",
       "      <td>273.836894</td>\n",
       "      <td>1438.994872</td>\n",
       "      <td>0.140265</td>\n",
       "      <td>617.672035</td>\n",
       "      <td>46.322212</td>\n",
       "      <td>32.388767</td>\n",
       "      <td>99.232105</td>\n",
       "      <td>113.747127</td>\n",
       "      <td>108.442276</td>\n",
       "      <td>111.190586</td>\n",
       "      <td>111.090898</td>\n",
       "      <td>7.719474e+07</td>\n",
       "      <td>13.394770</td>\n",
       "      <td>0.028507</td>\n",
       "      <td>6.376670e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.823100</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>-0.888700</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.331300</td>\n",
       "      <td>9.403300</td>\n",
       "      <td>9.488000</td>\n",
       "      <td>9.578000</td>\n",
       "      <td>1.065416e+07</td>\n",
       "      <td>16.564100</td>\n",
       "      <td>-0.136635</td>\n",
       "      <td>-8.257751e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.019600</td>\n",
       "      <td>1147.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>928.500000</td>\n",
       "      <td>-0.023575</td>\n",
       "      <td>363.250000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>16.958000</td>\n",
       "      <td>16.496500</td>\n",
       "      <td>16.717825</td>\n",
       "      <td>16.712175</td>\n",
       "      <td>6.643042e+07</td>\n",
       "      <td>43.676050</td>\n",
       "      <td>-0.015319</td>\n",
       "      <td>-1.407506e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.007000</td>\n",
       "      <td>1692.500000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>1346.500000</td>\n",
       "      <td>-0.001300</td>\n",
       "      <td>628.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>23.577650</td>\n",
       "      <td>22.859700</td>\n",
       "      <td>23.231300</td>\n",
       "      <td>23.210000</td>\n",
       "      <td>9.388688e+07</td>\n",
       "      <td>51.657850</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>2.866695e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.007300</td>\n",
       "      <td>2616.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>2024.500000</td>\n",
       "      <td>0.011825</td>\n",
       "      <td>997.250000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>219.074525</td>\n",
       "      <td>207.633350</td>\n",
       "      <td>214.079175</td>\n",
       "      <td>214.717500</td>\n",
       "      <td>1.347306e+08</td>\n",
       "      <td>61.836825</td>\n",
       "      <td>0.015759</td>\n",
       "      <td>1.430274e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.761400</td>\n",
       "      <td>20994.000000</td>\n",
       "      <td>7424.000000</td>\n",
       "      <td>6005.000000</td>\n",
       "      <td>19651.000000</td>\n",
       "      <td>0.879500</td>\n",
       "      <td>6123.000000</td>\n",
       "      <td>718.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>1189.000000</td>\n",
       "      <td>414.496700</td>\n",
       "      <td>405.666700</td>\n",
       "      <td>411.470000</td>\n",
       "      <td>409.970000</td>\n",
       "      <td>9.140814e+08</td>\n",
       "      <td>94.198000</td>\n",
       "      <td>0.146262</td>\n",
       "      <td>1.036267e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       TWITTER_SENTIMENT_DAILY_AVG  TWITTER_PUBLICATION_COUNT  \\\n",
       "count                  2246.000000                2246.000000   \n",
       "mean                     -0.011724                2225.603295   \n",
       "std                       0.065884                1892.479825   \n",
       "min                      -0.823100                 130.000000   \n",
       "25%                      -0.019600                1147.000000   \n",
       "50%                      -0.007000                1692.500000   \n",
       "75%                       0.007300                2616.000000   \n",
       "max                       0.761400               20994.000000   \n",
       "\n",
       "       TWITTER_NEG_SENTIMENT_COUNT  TWITTER_POS_SENTIMENT_COUNT  \\\n",
       "count                  2246.000000                  2246.000000   \n",
       "mean                    243.328139                   176.725289   \n",
       "std                     361.788078                   273.836894   \n",
       "min                       1.000000                     4.000000   \n",
       "25%                      84.000000                    64.000000   \n",
       "50%                     145.000000                   108.000000   \n",
       "75%                     254.000000                   192.000000   \n",
       "max                    7424.000000                  6005.000000   \n",
       "\n",
       "       TWITTER_NEUTRAL_SENTIMENT_CNT  NEWS_SENTIMENT_DAILY_AVG  \\\n",
       "count                    2246.000000               2246.000000   \n",
       "mean                     1728.593945                 -0.007657   \n",
       "std                      1438.994872                  0.140265   \n",
       "min                        87.000000                 -0.888700   \n",
       "25%                       928.500000                 -0.023575   \n",
       "50%                      1346.500000                 -0.001300   \n",
       "75%                      2024.500000                  0.011825   \n",
       "max                     19651.000000                  0.879500   \n",
       "\n",
       "       NEWS_PUBLICATION_COUNT  NEWS_NEG_SENTIMENT_COUNT  \\\n",
       "count             2246.000000               2246.000000   \n",
       "mean               786.969279                 25.896260   \n",
       "std                617.672035                 46.322212   \n",
       "min                 67.000000                  0.000000   \n",
       "25%                363.250000                  4.000000   \n",
       "50%                628.000000                 11.000000   \n",
       "75%                997.250000                 27.000000   \n",
       "max               6123.000000                718.000000   \n",
       "\n",
       "       NEWS_POS_SENTIMENT_COUNT  NEWS_NEUTRAL_SENTIMENT_COUNT      PX_HIGH  \\\n",
       "count               2246.000000                   2246.000000  2246.000000   \n",
       "mean                  18.248442                    142.836598   105.859928   \n",
       "std                   32.388767                     99.232105   113.747127   \n",
       "min                    0.000000                      0.000000    10.331300   \n",
       "25%                    3.000000                     75.000000    16.958000   \n",
       "50%                    8.000000                    122.000000    23.577650   \n",
       "75%                   20.000000                    188.000000   219.074525   \n",
       "max                  351.000000                   1189.000000   414.496700   \n",
       "\n",
       "            PX_LOW      PX_OPEN      PX_LAST        VOLUME      RSI_14D  \\\n",
       "count  2246.000000  2246.000000  2246.000000  2.246000e+03  2246.000000   \n",
       "mean    101.048998   103.517803   103.488381  1.146288e+08    52.864388   \n",
       "std     108.442276   111.190586   111.090898  7.719474e+07    13.394770   \n",
       "min       9.403300     9.488000     9.578000  1.065416e+07    16.564100   \n",
       "25%      16.496500    16.717825    16.712175  6.643042e+07    43.676050   \n",
       "50%      22.859700    23.231300    23.210000  9.388688e+07    51.657850   \n",
       "75%     207.633350   214.079175   214.717500  1.347306e+08    61.836825   \n",
       "max     405.666700   411.470000   409.970000  9.140814e+08    94.198000   \n",
       "\n",
       "          PX_TREND     PX_VTREND  \n",
       "count  2246.000000  2.246000e+03  \n",
       "mean      0.000178  1.118767e+05  \n",
       "std       0.028507  6.376670e+06  \n",
       "min      -0.136635 -8.257751e+07  \n",
       "25%      -0.015319 -1.407506e+06  \n",
       "50%       0.000435  2.866695e+04  \n",
       "75%       0.015759  1.430274e+06  \n",
       "max       0.146262  1.036267e+08  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dates of the data under study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2015-01-02', '2015-01-05', '2015-01-06', '2015-01-07',\n",
       "               '2015-01-08', '2015-01-09', '2015-01-12', '2015-01-13',\n",
       "               '2015-01-14', '2015-01-15',\n",
       "               ...\n",
       "               '2023-12-15', '2023-12-18', '2023-12-19', '2023-12-20',\n",
       "               '2023-12-21', '2023-12-22', '2023-12-26', '2023-12-27',\n",
       "               '2023-12-28', '2023-12-29'],\n",
       "              dtype='datetime64[ns]', name='date', length=2246, freq=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict[\"TSLA\"].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas Version: 1.5.0\n",
      "Numpy Version: 1.24.3\n",
      "System Version: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "mpl.rcParams['figure.figsize'] = (18, 10)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "print(f\"Pandas Version: {pd.__version__}\")\n",
    "print(f\"Numpy Version: {np.__version__}\")\n",
    "print(f\"System Version: {sys.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "win         = 15  # window size\n",
    "lahead      = [1, 7, 14, 30, 90] # Number of days ahead for prediction.\n",
    "deep        = 1   # Number of features considered\n",
    "n_ftrs      = 1   # 1 feature to be predicted\n",
    "tr_tst      = 0.8 # % of samples used for training\n",
    "serial_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 1 day(s) ahead.\n",
      "  Var Indep. 15. Rows 1792. Var dep samples 1792.\n",
      "Prediction 7 day(s) ahead.\n",
      "  Var Indep. 15. Rows 1788. Var dep samples 1788.\n",
      "Prediction 14 day(s) ahead.\n",
      "  Var Indep. 15. Rows 1782. Var dep samples 1782.\n",
      "Prediction 30 day(s) ahead.\n",
      "  Var Indep. 15. Rows 1769. Var dep samples 1769.\n",
      "Prediction 90 day(s) ahead.\n",
      "  Var Indep. 15. Rows 1721. Var dep samples 1721.\n"
     ]
    }
   ],
   "source": [
    "for stock in stock_list:\n",
    "    serial_dict[stock] = {}\n",
    "    for ahead in lahead:\n",
    "        df = df_dict[stock].copy()\n",
    "\n",
    "        # Window of relevant data\n",
    "        win_x = np.lib.stride_tricks.sliding_window_view(df.PX_OPEN.to_numpy(), window_shape = win)[::1]\n",
    "\n",
    "        # Shift the Y axis\n",
    "        Y= df.iloc[ahead+win:]['PX_OPEN']\n",
    "        X = pd.DataFrame.from_records(win_x)\n",
    "\n",
    "        # Cutting out records with no data in Y+ahead respecting the win+ahead offset\n",
    "        X = X.iloc[:-(ahead+1),:] # Skipping the gap in forecasting values\n",
    "        X.set_index(df.index[(win-1):-(ahead+1)],drop=True, inplace=True)\n",
    "\n",
    "        xm = X.mean(axis=1)\n",
    "        cX = X.sub(X.mean(axis=1), axis=0)\n",
    "\n",
    "        #  Scaling and storing ranges in vdd\n",
    "        mnx= round(min(cX.min())) # whole min\n",
    "        mxx= round(max(cX.max())) # whole max\n",
    "        vdd= pd.DataFrame({'mean':xm,'min':mnx,'max':mxx}) # DF with ranges\n",
    "        vdd.set_index(X.index,drop=True,inplace=True)\n",
    "\n",
    "        # Normalizing X and Y\n",
    "        cXn= cX.apply(lambda x: (x-mnx)/(mxx-mnx), axis=1)\n",
    "        cYn= pd.Series([((i-j)-mnx)/(mxx-mnx) for i,j in zip(Y.tolist(),xm.tolist())], index=Y.index)\n",
    "        cXn = cXn.astype('float32')\n",
    "        cYn = cYn.astype('float32')\n",
    "\n",
    "        # Data set preparation for modeling, starting from cXn and cYn\n",
    "        pmod   = int(cXn.shape[0]*tr_tst)  # 20% reserved for test data\n",
    "        trainX = cXn.iloc[:pmod,:]\n",
    "        trainY = cYn.iloc[:pmod]\n",
    "        testX  = cXn.iloc[pmod:,:]\n",
    "        testY  = cYn.iloc[pmod:]\n",
    "\n",
    "        serial_dict[stock][ahead] = {'x':X,'y':Y, 'nx':cXn,'ny':cYn, 'numt':pmod, 'vdd':vdd, \\\n",
    "                                     'trX':trainX,'trY':trainY, 'tsX':testX,'tsY':testY}\n",
    "\n",
    "#Checking info       \n",
    "for ahead in lahead:\n",
    "    print(\"Prediction {} day(s) ahead.\".format(ahead))\n",
    "    X = serial_dict['AAPL'][ahead]['trX']\n",
    "    Y = serial_dict['AAPL'][ahead]['trY']\n",
    "    print(\"  Var Indep. {}. Rows {}. Var dep samples {}.\".format(X.shape[1],X.shape[0],Y.shape[0]))\n",
    "tot_res['INP_SERIAL'] = serial_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdat = \"/data_processed/{:02}/input-output.pkl\".format(win)\n",
    "lpar  = [win, deep, n_ftrs,tr_tst]\n",
    "\n",
    "with open(fdat, 'wb') as file:\n",
    "    pickle.dump(path, file)\n",
    "    pickle.dump(fdat,file)\n",
    "    pickle.dump(lahead,file)\n",
    "    pickle.dump(lpar,file)\n",
    "    pickle.dump(stock_list,file)\n",
    "    pickle.dump(tot_res, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate preprocessing for Transformer multi-heading\n",
    "### Sentiment Analysis, RSI Technical Indicator, News and Price and Volume Trend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['AAPL', 'ADBE', 'AMZN', 'AVGO', 'CMCSA', 'COST', 'CSCO', 'GOOG', 'GOOGL', 'META', 'MSFT', 'NVDA', 'PEP', 'TMUS', 'TSLA'])\n"
     ]
    }
   ],
   "source": [
    "print(df_dict.keys()) # Stocks tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mwin  = 15  # multivariate window size\n",
    "mdeep = 8   # multivariate number of features considered\n",
    "m_ftrs= 1   # multivariate 1 feature to be predicted\n",
    "mserial_dict = {}\n",
    "\n",
    "for stock in stock_list:\n",
    "    mserial_dict[stock] = {}\n",
    "    df    = df_dict[stock].copy()\n",
    "    mdf = df[['PX_OPEN','RSI_14D','PX_TREND','PX_VTREND']]\n",
    "    df['TWITTER_PUBLICATION_COUNT'].replace(to_replace = 0, value = 1, inplace=True) # Replace 0 by 1\n",
    "\n",
    "    ss  = df['TWITTER_POS_SENTIMENT_COUNT'] / df['TWITTER_PUBLICATION_COUNT']\n",
    "    mdf.loc[:,'TWEETPR'] = ss\n",
    "\n",
    "    ss  = df['TWITTER_NEG_SENTIMENT_COUNT'] / df['TWITTER_PUBLICATION_COUNT']\n",
    "    mdf.loc[:,'TWEETNR'] = ss\n",
    "\n",
    "    df['NEWS_PUBLICATION_COUNT'].replace(to_replace = 0, value = 1, inplace=True)\n",
    "    \n",
    "    ss  = df['NEWS_POS_SENTIMENT_COUNT'] / df['NEWS_PUBLICATION_COUNT']\n",
    "    mdf.loc[:,'NEWSPR'] = ss \n",
    "\n",
    "    ss  = df['NEWS_NEG_SENTIMENT_COUNT'] / df['NEWS_PUBLICATION_COUNT']\n",
    "    mdf.loc[:,'NEWSNR'] = ss\n",
    "\n",
    "    if np.isinf(mdf).values.sum() > 0: # Check if there is any infinite value in the dataframe\n",
    "        pdb.set_trace()\n",
    "        \n",
    "    # mdf.columns\n",
    "    dfY   = mdf['PX_OPEN'].copy()\n",
    "    dfX   = mdf[['PX_OPEN','RSI_14D', 'PX_TREND','PX_VTREND', 'TWEETPR', 'TWEETNR', 'NEWSPR','NEWSNR']].copy()\n",
    "    idx   = dfX.index[(mwin-1):]\n",
    "    mX    = []\n",
    "    cols= dfX.columns\n",
    "\n",
    "    for i in range(len(dfX.columns)):\n",
    "        ss = windowing(dfX.iloc[:,i],mwin,m_ftrs,idx)\n",
    "        mX.append(ss.to_numpy())\n",
    "    mX = np.transpose(np.stack(mX,axis=1),(0,2,1))\n",
    "\n",
    "    for ahead in lahead:\n",
    "        mXl  = mX[:-(ahead+1),:,:]\n",
    "        mYl  = dfY.iloc[ahead+mwin:]\n",
    "        avmX = np.mean(mXl,axis=1)\n",
    "        avmXc= mXl-avmX[:,None,:]\n",
    "        pavX = pd.DataFrame(np.mean(mXl,axis=1),columns=dfX.columns)\n",
    "        pavX.set_index(idx[ahead+1:],drop=True,inplace=True)\n",
    "        mxmX = np.round(np.max(avmXc,axis=(0,1)),2)\n",
    "        mnmX = np.round(np.min(avmXc,axis=(0,1)),2)\n",
    "        mvdd = {'mean':pavX,'min':mnmX,'max':mxmX}\n",
    "        mXn  = (avmXc-mnmX[None,None,:])/(mxmX[None,None,:]-mnmX[None,None,:]+0.00001)\n",
    "        mYn  = ((mYl.to_numpy()-avmX[:,0])-mnmX[0])/(mxmX[0]-mnmX[0]+0.00001)\n",
    "\n",
    "        mXn = mXn.astype('float32')\n",
    "        mYn = mYn.astype('float32')\n",
    "\n",
    "        # Data set preparation for modeling, starting from cXn and cYn\n",
    "        pmod   = int(mXn.shape[0]*tr_tst)  # 20% of data for testing\n",
    "\n",
    "        mtrainX = mXn[:pmod,:,:]\n",
    "        mtrainY = mYn[:pmod]\n",
    "        mtestX = mXn[pmod:,:,:]\n",
    "        mtestY = mYn[pmod:]\n",
    "        xdx   = idx[:-(ahead+1)]\n",
    "        ydx   = mYl[pmod:].index  # Taking out the indexes for plotting\n",
    "\n",
    "        if np.isinf(mtrainX).any():\n",
    "            print('Stock {} ahead: {} has nans.'.format(stock,ahead))\n",
    "            print(mtrainX)\n",
    "            pdb.set_trace()\n",
    "        if np.isnan(mtrainX).any():\n",
    "            print('Stock {} ahead: {} has nans.'.format(stock,ahead))\n",
    "            print(mtrainX)\n",
    "            pdb.set_trace()\n",
    "        if np.isnan(mtestX).any():\n",
    "            print('Stock {} ahead: {} has nans.'.format(stock,ahead))\n",
    "            print(mtestX)\n",
    "        mserial_dict[stock][ahead] = {'x':mXl,'y':mYl,'nx':mXn,'ny':mYn,'numt':pmod, \\\n",
    "                                      'vdd':mvdd, 'trX':mtrainX,'trY':mtrainY, \\\n",
    "                                      'tsX':mtestX,'tsY':mtestY,'cnms':cols,\\\n",
    "                                      'idtest':xdx[pmod:]}\n",
    "\n",
    "tot_res['INP_MSERIAL'] = mserial_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([1, 7, 14, 30, 90])\n",
      "(2224, 15, 8)\n"
     ]
    }
   ],
   "source": [
    "print(tot_res['INP_MSERIAL']['TSLA'].keys()) # Check the times are 1, 7, 14, 30 and 90 days\n",
    "print(tot_res['INP_MSERIAL']['TSLA'][7]['x'].shape) # Check the dimension of the data for each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdat = \"data_processed/{:02}/m-input-output.pkl\".format(win)\n",
    "\n",
    "lpar = [mwin, mdeep, n_ftrs, tr_tst]\n",
    "\n",
    "with open(fdat, 'wb') as file:\n",
    "    # dump information to that file\n",
    "    pickle.dump(path, file)\n",
    "    pickle.dump(fdat, file)\n",
    "    pickle.dump(lahead, file)\n",
    "    pickle.dump(lpar, file)\n",
    "    pickle.dump(stock_list, file)\n",
    "    pickle.dump(tot_res, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['x', 'y', 'nx', 'ny', 'numt', 'vdd', 'trX', 'trY', 'tsX', 'tsY', 'cnms', 'idtest'])\n",
      "Index(['PX_OPEN', 'RSI_14D', 'PX_TREND', 'PX_VTREND', 'TWEETPR', 'TWEETNR',\n",
      "       'NEWSPR', 'NEWSNR'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(mserial_dict['TSLA'][7].keys())\n",
    "print(mserial_dict['TSLA'][7]['cnms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PX_OPEN', 'RSI_14D', 'PX_TREND', 'PX_VTREND', 'TWEETPR', 'TWEETNR',\n",
       "       'NEWSPR', 'NEWSNR'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mserial_dict['TSLA'][7]['cnms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<details>\n",
       "<summary>Click to view session information</summary>\n",
       "<pre>\n",
       "-----\n",
       "matplotlib          3.6.0\n",
       "mpl_toolkits        NA\n",
       "numpy               1.24.3\n",
       "pandas              1.5.0\n",
       "scipy               1.9.1\n",
       "seaborn             0.12.1\n",
       "session_info        1.0.0\n",
       "-----\n",
       "</pre>\n",
       "<details>\n",
       "<summary>Click to view modules imported as dependencies</summary>\n",
       "<pre>\n",
       "PIL                 9.2.0\n",
       "asttokens           NA\n",
       "backcall            0.2.0\n",
       "beta_ufunc          NA\n",
       "binom_ufunc         NA\n",
       "colorama            0.4.5\n",
       "cycler              0.10.0\n",
       "cython_runtime      NA\n",
       "dateutil            2.8.2\n",
       "debugpy             1.6.3\n",
       "decorator           5.1.1\n",
       "entrypoints         0.4\n",
       "executing           1.1.1\n",
       "hypergeom_ufunc     NA\n",
       "ipykernel           6.16.0\n",
       "jedi                0.18.1\n",
       "kiwisolver          1.4.4\n",
       "nbinom_ufunc        NA\n",
       "ncf_ufunc           NA\n",
       "nt                  NA\n",
       "ntsecuritycon       NA\n",
       "packaging           21.3\n",
       "parso               0.8.3\n",
       "pickleshare         0.7.5\n",
       "pkg_resources       NA\n",
       "prompt_toolkit      3.0.31\n",
       "psutil              5.9.2\n",
       "pure_eval           0.2.2\n",
       "pydev_ipython       NA\n",
       "pydevconsole        NA\n",
       "pydevd              2.8.0\n",
       "pydevd_file_utils   NA\n",
       "pydevd_plugins      NA\n",
       "pydevd_tracing      NA\n",
       "pygments            2.13.0\n",
       "pyparsing           3.0.9\n",
       "pythoncom           NA\n",
       "pytz                2022.4\n",
       "pywin32_bootstrap   NA\n",
       "pywin32_system32    NA\n",
       "pywintypes          NA\n",
       "six                 1.16.0\n",
       "stack_data          0.5.1\n",
       "statsmodels         0.13.2\n",
       "tornado             6.2\n",
       "traitlets           5.4.0\n",
       "wcwidth             0.2.5\n",
       "win32api            NA\n",
       "win32com            NA\n",
       "win32security       NA\n",
       "zmq                 24.0.1\n",
       "zoneinfo            NA\n",
       "</pre>\n",
       "</details> <!-- seems like this ends pre, so might as well be explicit -->\n",
       "<pre>\n",
       "-----\n",
       "IPython             8.5.0\n",
       "jupyter_client      7.4.2\n",
       "jupyter_core        4.11.1\n",
       "-----\n",
       "Python 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]\n",
       "Windows-10-10.0.22621-SP0\n",
       "-----\n",
       "Session information updated at 2024-02-22 15:57\n",
       "</pre>\n",
       "</details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import session_info\n",
    "session_info.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
